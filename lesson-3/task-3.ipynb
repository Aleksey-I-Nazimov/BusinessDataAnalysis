{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b0c2d95",
   "metadata": {},
   "source": [
    "1. обучить несколько разных моделей на наборе данных ССЗ (train_case2.csv): логрег, бустинг, лес и т.д - на ваш выбор 2-3 варианта\n",
    "2. при обучении моделей обязательно использовать кроссвалидацию\n",
    "3. вывести сравнение полученных моделей по основным метрикам классификации: pr/rec/auc/f_score (можно в виде таблицы, где строки - модели, а столбцы - метрики)\n",
    "4. сделать выводы о том, какая модель справилась с задачей лучше других\n",
    "5. (опциональный вопрос) какая метрика (precision_recall_curve или roc_auc_curve) больше подходит в случае сильного дисбаланса классов? (когда объектов одного из классов намного больше чем другого). \n",
    "\n",
    "p.s.В вопросе проще разобраться, если вспомнить оси на графике roc auc curve и рассмотреть такой пример:\n",
    "\n",
    "Имеется 100000 объектов, из которых только 100 - класс \"1\" (99900 - класс \"0\", соответственно). \n",
    "Допустим, у нас две модели:\n",
    "\n",
    "- первая помечает 100 объектов как класс 1, но TP = 90\n",
    "- вторая помечает 1000 объектов как класс 1, но TP такой же - 90\n",
    "\n",
    "Какая модель лучше и почему? И что позволяет легче сделать вывод - roc_auc_curve или precision_recall_curve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ae737e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_row_number(data_frame):\n",
    "    return data_frame.shape[0];\n",
    "\n",
    "def print_columns(data_frame):\n",
    "    print (\"  --> Columns {}\".format(data_frame.columns));\n",
    "\n",
    "def analyze_class_balance (data_frame,feature_name,target_positive=1,target_negative=0):\n",
    "    positive_number = get_row_number(data_frame[data_frame[feature_name]==target_positive]);\n",
    "    negative_number = get_row_number(data_frame[data_frame[feature_name]==target_negative]);\n",
    "    print (\"  --> Found {} p/n: {}/{}\".format(feature_name,positive_number,negative_number));\n",
    "    return (positive_number,negative_number,positive_number+negative_number,feature_name);\n",
    "\n",
    "def select_columns(data_frame,columns):\n",
    "    new_data_frame = data_frame[['{}'.format(c) for c in columns]].copy(deep=True);\n",
    "    return new_data_frame;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "59129d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv(\"train.csv\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a31dec70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.095844</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.052948</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.049364</td>\n",
       "      <td>0.008805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.294379</td>\n",
       "      <td>0.099477</td>\n",
       "      <td>0.223931</td>\n",
       "      <td>0.054650</td>\n",
       "      <td>0.216627</td>\n",
       "      <td>0.093420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic   severe_toxic        obscene         threat  \\\n",
       "count  159571.000000  159571.000000  159571.000000  159571.000000   \n",
       "mean        0.095844       0.009996       0.052948       0.002996   \n",
       "std         0.294379       0.099477       0.223931       0.054650   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "              insult  identity_hate  \n",
       "count  159571.000000  159571.000000  \n",
       "mean        0.049364       0.008805  \n",
       "std         0.216627       0.093420  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.000000       0.000000  \n",
       "50%         0.000000       0.000000  \n",
       "75%         0.000000       0.000000  \n",
       "max         1.000000       1.000000  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ebcf6955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   id             159571 non-null  object\n",
      " 1   comment_text   159571 non-null  object\n",
      " 2   toxic          159571 non-null  int64 \n",
      " 3   severe_toxic   159571 non-null  int64 \n",
      " 4   obscene        159571 non-null  int64 \n",
      " 5   threat         159571 non-null  int64 \n",
      " 6   insult         159571 non-null  int64 \n",
      " 7   identity_hate  159571 non-null  int64 \n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 9.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data_frame.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b44fb774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  --> Columns Index(['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat',\n",
      "       'insult', 'identity_hate'],\n",
      "      dtype='object')\n",
      "  --> Found id p/n: 0/0\n",
      "  --> Found comment_text p/n: 0/0\n",
      "  --> Found toxic p/n: 15294/144277\n",
      "  --> Found severe_toxic p/n: 1595/157976\n",
      "  --> Found obscene p/n: 8449/151122\n",
      "  --> Found threat p/n: 478/159093\n",
      "  --> Found insult p/n: 7877/151694\n",
      "  --> Found identity_hate p/n: 1405/158166\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Balance analysis:---------------------------------------\n",
    "data_frame = pd.read_csv(\"train.csv\")\n",
    "\n",
    "print_columns(data_frame);\n",
    "for column in data_frame.columns:\n",
    "    analyze_class_balance(data_frame,column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1497a8e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                             comment_text\n",
       " 0       Explanation\\nWhy the edits made under my usern...\n",
       " 1       D'aww! He matches this background colour I'm s...\n",
       " 2       Hey man, I'm really not trying to edit war. It...\n",
       " 3       \"\\nMore\\nI can't make any real suggestions on ...\n",
       " 4       You, sir, are my hero. Any chance you remember...\n",
       " ...                                                   ...\n",
       " 159566  \":::::And for the second time of asking, when ...\n",
       " 159567  You should be ashamed of yourself \\n\\nThat is ...\n",
       " 159568  Spitzer \\n\\nUmm, theres no actual article for ...\n",
       " 159569  And it looks like it was actually you who put ...\n",
       " 159570  \"\\nAnd ... I really don't think you understand...\n",
       " \n",
       " [159571 rows x 1 columns],\n",
       "         threat\n",
       " 0            0\n",
       " 1            0\n",
       " 2            0\n",
       " 3            0\n",
       " 4            0\n",
       " ...        ...\n",
       " 159566       0\n",
       " 159567       0\n",
       " 159568       0\n",
       " 159569       0\n",
       " 159570       0\n",
       " \n",
       " [159571 rows x 1 columns])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting X,Y:-------------------------------------------\n",
    "TARGET='threat'\n",
    "\n",
    "X = select_columns(data_frame,['comment_text']);\n",
    "Y = select_columns(data_frame,[TARGET])\n",
    "(X,Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b3e43852",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "original_comments = [c for c in X['comment_text']]\n",
    "\n",
    "# print(\"  --> Original comments:\\n {}\".format(original_comments[:10]));\n",
    "\n",
    "assumed_features = 1000\n",
    "vectorizer = TfidfVectorizer(max_features=assumed_features)\n",
    "vectorized_comments = vectorizer.fit_transform(original_comments);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1a1d4a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(        0    1    2         3    4    5    6    7    8    9    ...  990  991  \\\n",
       " 0       0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       " 1       0.0  0.0  0.0  0.392295  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       " 2       0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       " 3       0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       " 4       0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       " ...     ...  ...  ...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       " 159566  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       " 159567  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       " 159568  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       " 159569  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       " 159570  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       " \n",
       "         992  993  994  995  996       997       998       999  \n",
       " 0       0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  \n",
       " 1       0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  \n",
       " 2       0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  \n",
       " 3       0.0  0.0  0.0  0.0  0.0  0.046977  0.000000  0.123425  \n",
       " 4       0.0  0.0  0.0  0.0  0.0  0.372557  0.000000  0.000000  \n",
       " ...     ...  ...  ...  ...  ...       ...       ...       ...  \n",
       " 159566  0.0  0.0  0.0  0.0  0.0  0.133020  0.096587  0.000000  \n",
       " 159567  0.0  0.0  0.0  0.0  0.0  0.277192  0.000000  0.364144  \n",
       " 159568  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  \n",
       " 159569  0.0  0.0  0.0  0.0  0.0  0.104653  0.000000  0.000000  \n",
       " 159570  0.0  0.0  0.0  0.0  0.0  0.147821  0.000000  0.000000  \n",
       " \n",
       " [159571 rows x 1000 columns],\n",
       "         threat\n",
       " 0            0\n",
       " 1            0\n",
       " 2            0\n",
       " 3            0\n",
       " 4            0\n",
       " ...        ...\n",
       " 159566       0\n",
       " 159567       0\n",
       " 159568       0\n",
       " 159569       0\n",
       " 159570       0\n",
       " \n",
       " [159571 rows x 1 columns])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "xv = pd.DataFrame([np.ravel(row.todense()) for row in vectorized_comments])\n",
    "yv = Y.copy();\n",
    "(xv,yv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "408897f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape=(79785, 1000)\n",
      "X test shape=(79786, 1000)\n",
      "Y train shape=(79785, 1)\n",
      "Y test shape=(79786, 1)\n",
      "  --> Found threat p/n: 246/79540\n",
      "  --> Found threat p/n: 232/79553\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(232, 79553, 79785, 'threat')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Splitting for test and train sets:-----------------------------------\n",
    "# train---test----train-----test-----\n",
    "x_train, x_test, y_train, y_test = train_test_split(xv,yv,train_size=0.5,shuffle=True,random_state=1)\n",
    "print(\"X train shape={}\".format(x_train.shape));\n",
    "print(\"X test shape={}\".format(x_test.shape));\n",
    "print(\"Y train shape={}\".format(y_train.shape));\n",
    "print(\"Y test shape={}\".format(y_test.shape));\n",
    "\n",
    "# Additional class balance info:---------------------------------------\n",
    "analyze_class_balance(y_test,TARGET)\n",
    "analyze_class_balance(y_train,TARGET)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "84f0fea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BalancedRandomForestClassifier classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95     79540\n",
      "           1       0.03      0.84      0.05       246\n",
      "\n",
      "    accuracy                           0.91     79786\n",
      "   macro avg       0.51      0.87      0.50     79786\n",
      "weighted avg       1.00      0.91      0.95     79786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "clf = BalancedRandomForestClassifier(n_estimators=500,max_depth=250, random_state=0)\n",
    "clf.fit(x_train,y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test);\n",
    "class_report = classification_report(y_test,y_pred);\n",
    "print (\"BalancedRandomForestClassifier classification report: \\n{}\".format(class_report));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6c4a0096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BalancedRandomForestClassifier cross-validation score: 0.9638911009964394\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "clf = BalancedRandomForestClassifier(n_estimators=500,max_depth=250, random_state=0)\n",
    "\n",
    "cv_scores = cross_val_score(clf, x_train, y_train, cv=3, scoring='roc_auc')\n",
    "cv_score = np.mean(cv_scores)\n",
    "print('BalancedRandomForestClassifier cross-validation score: {}'.format(cv_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "acabb674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     79540\n",
      "           1       0.00      0.00      0.00       246\n",
      "\n",
      "    accuracy                           1.00     79786\n",
      "   macro avg       0.50      0.50      0.50     79786\n",
      "weighted avg       0.99      1.00      1.00     79786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C=0.1, solver='sag')\n",
    "clf.fit(x_train,y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test);\n",
    "class_report = classification_report(y_test,y_pred);\n",
    "print (\"Logistic regression classification report: \\n{}\".format(class_report));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "eac7a351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression cross-validation score: 0.9629875270376479\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=0.1, solver='sag')\n",
    "\n",
    "cv_scores = cross_val_score(clf, x_train, y_train, cv=3, scoring='roc_auc')\n",
    "cv_score = np.mean(cv_scores)\n",
    "print('Logistic regression cross-validation score: {}'.format(cv_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bdf7f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
