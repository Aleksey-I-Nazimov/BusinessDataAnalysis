{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3d218c7",
   "metadata": {},
   "source": [
    "1. обучить несколько разных моделей на наборе данных ССЗ (train_case2.csv): логрег, бустинг, лес и т.д - на ваш выбор 2-3 варианта\n",
    "2. при обучении моделей обязательно использовать кроссвалидацию\n",
    "3. вывести сравнение полученных моделей по основным метрикам классификации: pr/rec/auc/f_score (можно в виде таблицы, где строки - модели, а столбцы - метрики)\n",
    "4. сделать выводы о том, какая модель справилась с задачей лучше других\n",
    "5. (опциональный вопрос) какая метрика (precision_recall_curve или roc_auc_curve) больше подходит в случае сильного дисбаланса классов? (когда объектов одного из классов намного больше чем другого). \n",
    "\n",
    "p.s.В вопросе проще разобраться, если вспомнить оси на графике roc auc curve и рассмотреть такой пример:\n",
    "\n",
    "Имеется 100000 объектов, из которых только 100 - класс \"1\" (99900 - класс \"0\", соответственно). \n",
    "Допустим, у нас две модели:\n",
    "\n",
    "- первая помечает 100 объектов как класс 1, но TP = 90\n",
    "- вторая помечает 1000 объектов как класс 1, но TP такой же - 90\n",
    "\n",
    "Какая модель лучше и почему? И что позволяет легче сделать вывод - roc_auc_curve или precision_recall_curve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89cb605e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_row_number(data_frame):\n",
    "    return data_frame.shape[0];\n",
    "\n",
    "def print_columns(data_frame):\n",
    "    print (\"  --> Columns {}\".format(data_frame.columns));\n",
    "\n",
    "def analyze_class_balance (data_frame,feature_name,target_positive=1,target_negative=0):\n",
    "    positive_number = get_row_number(data_frame[data_frame[feature_name]==target_positive]);\n",
    "    negative_number = get_row_number(data_frame[data_frame[feature_name]==target_negative]);\n",
    "    print (\"  --> Found {} p/n: {}/{}\".format(feature_name,positive_number,negative_number));\n",
    "    return (positive_number,negative_number,positive_number+negative_number,feature_name);\n",
    "\n",
    "def select_columns(data_frame,columns):\n",
    "    new_data_frame = data_frame[['{}'.format(c) for c in columns]].copy(deep=True);\n",
    "    return new_data_frame;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9520c8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv(\"train.csv\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e746014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.095844</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.052948</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.049364</td>\n",
       "      <td>0.008805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.294379</td>\n",
       "      <td>0.099477</td>\n",
       "      <td>0.223931</td>\n",
       "      <td>0.054650</td>\n",
       "      <td>0.216627</td>\n",
       "      <td>0.093420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic   severe_toxic        obscene         threat  \\\n",
       "count  159571.000000  159571.000000  159571.000000  159571.000000   \n",
       "mean        0.095844       0.009996       0.052948       0.002996   \n",
       "std         0.294379       0.099477       0.223931       0.054650   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "              insult  identity_hate  \n",
       "count  159571.000000  159571.000000  \n",
       "mean        0.049364       0.008805  \n",
       "std         0.216627       0.093420  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.000000       0.000000  \n",
       "50%         0.000000       0.000000  \n",
       "75%         0.000000       0.000000  \n",
       "max         1.000000       1.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6df4e2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   id             159571 non-null  object\n",
      " 1   comment_text   159571 non-null  object\n",
      " 2   toxic          159571 non-null  int64 \n",
      " 3   severe_toxic   159571 non-null  int64 \n",
      " 4   obscene        159571 non-null  int64 \n",
      " 5   threat         159571 non-null  int64 \n",
      " 6   insult         159571 non-null  int64 \n",
      " 7   identity_hate  159571 non-null  int64 \n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 9.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data_frame.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "170350d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  --> Columns Index(['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat',\n",
      "       'insult', 'identity_hate'],\n",
      "      dtype='object')\n",
      "  --> Found id p/n: 0/0\n",
      "  --> Found comment_text p/n: 0/0\n",
      "  --> Found toxic p/n: 15294/144277\n",
      "  --> Found severe_toxic p/n: 1595/157976\n",
      "  --> Found obscene p/n: 8449/151122\n",
      "  --> Found threat p/n: 478/159093\n",
      "  --> Found insult p/n: 7877/151694\n",
      "  --> Found identity_hate p/n: 1405/158166\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Balance analysis:---------------------------------------\n",
    "data_frame = pd.read_csv(\"train.csv\")\n",
    "\n",
    "print_columns(data_frame);\n",
    "for column in data_frame.columns:\n",
    "    analyze_class_balance(data_frame,column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c08a857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                             comment_text\n",
       " 0       Explanation\\nWhy the edits made under my usern...\n",
       " 1       D'aww! He matches this background colour I'm s...\n",
       " 2       Hey man, I'm really not trying to edit war. It...\n",
       " 3       \"\\nMore\\nI can't make any real suggestions on ...\n",
       " 4       You, sir, are my hero. Any chance you remember...\n",
       " ...                                                   ...\n",
       " 159566  \":::::And for the second time of asking, when ...\n",
       " 159567  You should be ashamed of yourself \\n\\nThat is ...\n",
       " 159568  Spitzer \\n\\nUmm, theres no actual article for ...\n",
       " 159569  And it looks like it was actually you who put ...\n",
       " 159570  \"\\nAnd ... I really don't think you understand...\n",
       " \n",
       " [159571 rows x 1 columns],\n",
       "         toxic\n",
       " 0           0\n",
       " 1           0\n",
       " 2           0\n",
       " 3           0\n",
       " 4           0\n",
       " ...       ...\n",
       " 159566      0\n",
       " 159567      0\n",
       " 159568      0\n",
       " 159569      0\n",
       " 159570      0\n",
       " \n",
       " [159571 rows x 1 columns])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case with toxic:----------------------------------------\n",
    "X = select_columns(data_frame,['comment_text']);\n",
    "Y = select_columns(data_frame,['toxic'])\n",
    "(X,Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "253f9c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  --> Original comments:\n",
      " [\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\", \"D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)\", \"Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.\", '\"\\nMore\\nI can\\'t make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It\\'s listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"', \"You, sir, are my hero. Any chance you remember what page that's on?\", '\"\\n\\nCongratulations from me as well, use the tools well. \\xa0· talk \"', 'COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK', \"Your vandalism to the Matt Shirvington article has been reverted.  Please don't do it again, or you will be banned.\", \"Sorry if the word 'nonsense' was offensive to you. Anyway, I'm not intending to write anything in the article(wow they would jump on me for vandalism), I'm merely requesting that it be more encyclopedic so one can use it for school as a reference. I have been to the selective breeding page but it's almost a stub. It points to 'animal breeding' which is a short messy article that gives you no info. There must be someone around with expertise in eugenics? 93.161.107.169\", 'alignment on this subject and which are contrary to those of DuLithgow']\n",
      "  --> Vectorized comments:\n",
      "  (0, 590)\t0.17999567646166315\n",
      "  (0, 782)\t0.20596764536754567\n",
      "  (0, 626)\t0.1392931223939808\n",
      "  (0, 843)\t0.14093926815611665\n",
      "  (0, 353)\t0.13761398341904169\n",
      "  (0, 847)\t0.2632064676932911\n",
      "  (0, 718)\t0.23126682117221947\n",
      "  (0, 274)\t0.1601598164633619\n",
      "  (0, 651)\t0.15064262074924456\n",
      "  (0, 75)\t0.08535409573423615\n",
      "  (0, 572)\t0.20243115843922188\n",
      "  (0, 105)\t0.13943193574768836\n",
      "  (0, 54)\t0.20871118480136833\n",
      "  (0, 790)\t0.16352284189476785\n",
      "  (0, 604)\t0.11013037667819696\n",
      "  (0, 472)\t0.1510895112254187\n",
      "  (0, 865)\t0.16076631019130969\n",
      "  (0, 732)\t0.24944902580898395\n",
      "  (0, 951)\t0.18667430100683433\n",
      "  (0, 916)\t0.2968947555902044\n",
      "  (0, 561)\t0.13865871108487962\n",
      "  (0, 902)\t0.22293522861949255\n",
      "  (0, 516)\t0.2014209421263372\n",
      "  (0, 290)\t0.20600163413167522\n",
      "  (0, 856)\t0.21287075728528218\n",
      "  (0, 962)\t0.17452114632219456\n",
      "  (0, 319)\t0.2900642458905523\n",
      "  (1, 921)\t0.29989177079179924\n",
      "  (1, 3)\t0.3922954222850447\n",
      "  (1, 463)\t0.43016126503093177\n",
      "  (1, 21)\t0.4112636187084551\n",
      "  (1, 854)\t0.2541287535397115\n",
      "  (1, 970)\t0.17254714319307904\n",
      "  (1, 118)\t0.43425419639051405\n",
      "  (1, 871)\t0.14688496523464223\n",
      "  (1, 399)\t0.24236183299393851\n",
      "  (1, 843)\t0.1968442309865772\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "original_comments = [original_comment for original_comment in X['comment_text']]\n",
    "\n",
    "print(\"  --> Original comments:\\n {}\".format(original_comments[:10]));\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=100)\n",
    "vectorized_comments = vectorizer.fit_transform(original_comments);\n",
    "for \n",
    "\n",
    "print(\"  --> Vectorized comments:\\n{}\".format(vectorized_comments[:2]));\n",
    "\n",
    "\n",
    "# Case with toxic:----------------------------------------\n",
    "\n",
    "#vectorizer = TfidfVectorizer()\n",
    "\n",
    "#corpus = v\n",
    "\n",
    "\n",
    "#corpus = [\n",
    "#     'This is the first document.',\n",
    "#     'This document is the second document.',\n",
    "#     'And this is the third one.',\n",
    "#     'Is this the first document?',\n",
    "#]\n",
    "\n",
    "#vectorizer = TfidfVectorizer()\n",
    "#X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# vectorizer.get_feature_names_out()\n",
    "\n",
    "#print (\"{}\".format(X));\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830b0b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e34e7e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7832092b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616b4f34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb76b13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
